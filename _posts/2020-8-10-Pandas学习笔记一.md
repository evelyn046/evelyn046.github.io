---
title: Pandas 学习笔记（一）
author: Evelyn
date: 2020-08-10 14:42:00 +0800
categories: [学习笔记, Python]
tags: [Python, 数据分析, Pandas]
---

前些天用到了一点pandas处理excel文档，那索性就系统学习一下Pandas吧。

Pandas:一个开源的python类库，用于数据分析、数据处理、数据可视化
    - 高性能
    - 容易使用的数据结构
    - 容易使用的数据分析工具

安装方法：
``pip instal pandas``

# 01 Pandas数据读取
pandas需要先读取表格类型数据，然后分析
- csv、tsv、txt 逗号/tab分隔的纯文本文件 —— pd.read_csv
- excel 微软xls/xlsx文件 —— pd.read_excel
- mysql 关系型数据库表 —— pd.read_sql
(1) 读取CSV，使用默认的标题行、逗号分隔符

``f = pd.read_csv(fpath)``

(2) 读取txt文件，自己指定分隔符、列名
```
pvuv = pd.read_csv(
    fpath,
    sep="\t", # 分隔符为\t
    header=None, # 文件中没有标题行
    names=['pdate', 'pv', 'uv'] # 数据中无列名，自己指定列名
)

```

（3）读取excel文件
```
f = pd.read_excel(fpath)
```

(4) 读取MySQL数据库
```
import pymysql
conn = pymysql.connect(
        host='127.0.0.1',
        user='root',
        password='12345678',
        database='test',
        charset='utf8'
    )

mysql_page = pd.read_sql("select * from crazyant_pvuv", con=conn) #(sql语句,数据库连接)
```

# 02 Pandas数据结构（DataFrame & Series）

DataFrame: 二维数据，整个表格对象，多行多列
- df.index
- df.columns

Series: 一维数据，一行或一列

(1)Series

Series是一种类似于一维数组的对象，它由一组数据（不同数据类型）以及一组与之相关的数据标签（即**索引**）组成

三种创建Series的方法

- 使用list产生最简单的Series
  ```
    s1 = pd.Series([1,'a',5.2,7])
    
    #左侧为索引，右侧为数据
    0      1
    1      a
    2    5.2
    3      7

    s1.index #获取索引
    s1.values #获取数据
  ```
- 创建一个具有标签索引的Series
  ```
    s2 = pd.Series([1, 'a', 5.2, 7], index=['d','b','a','c'])

    d      1
    b      a
    a    5.2
    c      7

  ```
- 使用Python字典创建Series
  ```
    s3={'Ohio':35000,'Texas':72000,'Oregon':16000,'Utah':5000}
    
    #字典的key对应索引，value对应值
    Ohio      35000
    Texas     72000
    Oregon    16000
    Utah       5000
  ```
根据标签索引查询数据 —— 类似Python的字典

![]({{ "/assets/img/2020-08-07-17-21-28.png" |  }})

```
s2[['b','a']] #series中可以传入多个标签，获取对应的值，[[]]会访问多列数据
```

(2)DataFrame

DataFrame是一个表格型的数据结构

- 每列可以是不同的值类型（数值、字符串、布尔值等）
- 既有行索引index,也有列索引columns
- 可以被看做由Series组成的字典

创建方法：

- 直接从数据源创建（参考01读取文件）
- 根据多个字典序列创建
  ```
  #字典的key对应列名，value对应列的值，每一列的下标变成了每一行的索引
    data={
            'state':['Ohio','Ohio','Ohio','Nevada','Nevada'],
            'year':[2000,2001,2002,2001,2002],
            'pop':[1.5,1.7,3.6,2.4,2.9]
        }
    df = pd.DataFrame(data)
  ```
    ![]({{ "/assets/img/2020-08-07-17-27-54.png" |  }})

(3)从DataFrame中查询出Series

- 如果只查询一行、一列，返回的是pd.Series
- 如果查询多行、多列，返回的是pd.DataFrame

- 查询一列 —— index是行索引
  ```
    df['year']
    # 0    2000
      1    2001
      2    2002
      3    2001
      4    2002
      Name: year, dtype: int64
    
  ```
- 查询多列
  ```
    df[['year', 'pop']]
    #    	year	pop
        0	2000	1.5
        1	2001	1.7
        2	2002	3.6
        3	2001	2.4
        4	2002	2.9
  ```
- 查询一行 —— index是列名
  ```
    df.loc[1]
    # state    Ohio
      year     2001
      pop       1.7
      Name: 1, dtype: object
  ```
- 查询多行
  ```
  # python的切片不包含末尾元素，但是loc会包含最后一行
    df.loc[1:3]
    #  state	year	pop
     1	Ohio	2001	1.7
     2	Ohio	2002	3.6
     3	Nevada	2001	2.4

  ```

# 03 Pandas查询数据
  
方法：
- **df.loc方法**，根据行、列的标签值查询
- df.iloc方法，根据行、列的数字位置查询
- df.where方法
- df.query方法

Pandas使用df.loc查询数据的方法(适用各个维度)
- 使用单个label值查询数据
- 使用值列表批量查询
- 使用数值区间进行范围查询
- 使用条件表达式查询
- 调用函数查询

(1)使用单个label值查询数据

行或者列，都可以只传入单个值，实现精确匹配

```
# 得到单个值
df.loc['2018-01-03', 'bWendu']
# 2

# 得到一个Series
df.loc['2018-01-03', ['bWendu', 'yWendu']]
# bWendu     2
  yWendu    -5
  Name: 2018-01-03, dtype: object

```

(2)使用值列表批量查询

```
# 得到Series
df.loc[['2018-01-03','2018-01-04','2018-01-05'], 'bWendu']
# ymd
  2018-01-03    2
  2018-01-04    0
  2018-01-05    3
  Name: bWendu, dtype: int32

# 得到DataFrame
df.loc[['2018-01-03','2018-01-04','2018-01-05'], ['bWendu', 'yWendu']]

#           bWendu  yWendu
    ymd		
    2018-01-03	2	-5
    2018-01-04	0	-8
    2018-01-05	3	-6

```
(3)使用数值区间进行范围查询

区间既包含开始，也包含结束

```
# 行index按区间
df.loc['2018-01-03':'2018-01-05', 'bWendu']

#     ymd
    2018-01-03    2
    2018-01-04    0
    2018-01-05    3
    Name: bWendu, dtype: int32

# 列index按区间
df.loc['2018-01-03', 'bWendu':'fengxiang']

# bWendu        2
  yWendu       -5
  tianqi       多云
  fengxiang    北风
  Name: 2018-01-03, dtype: object

# 行和列都按区间查询——二维
df.loc['2018-01-03':'2018-01-05', 'bWendu':'fengxiang']

#	bWendu	yWendu	tianqi	fengxiang
ymd				
2018-01-03	2	-5	多云	北风
2018-01-04	0	-8	阴	东北风
2018-01-05	3	-6	多云~晴	西北风

```

(4)**使用条件表达式查询**

简单条件查询，最低温度低于-10度的列表

```
def.loc[df["ywendu"]<10, :]
```
![]({{ "/assets/img/2020-08-07-17-58-41.png" |  }})

复杂条件查询

注意，组合条件用&符号合并，每个条件判断都得带括号

```
# 查询最高温度小于30度，并且最低温度大于15度，并且是晴天，并且天气为优的数据
df.loc[(df["bWendu"]<=30) & (df["yWendu"]>=15) & (df["tianqi"]=='晴') & (df["aqiLevel"]==1), :]
```
![]({{ "/assets/img/2020-08-07-18-00-18.png" |  }})

(5)调用函数查询
```
# 编写自己的函数，查询9月份，空气质量好的数据
def query_my_data(df):
    return df.index.str.startswith("2018-09") & (df["aqiLevel"]==1)
    
df.loc[query_my_data, :]
```
![]({{ "/assets/img/2020-08-07-18-03-13.png" |  }})

# 04 Pandas新增数据列

方法

- 直接赋值
- df.apply方法
- df.assign方法
- 按条件选择分组分别赋值

![]({{ "/assets/img/2020-08-07-18-34-20.png" |  }})

(1)直接赋值
```
# 修改列，清理温度列，变成数字类型，替换掉温度的后缀℃
df.loc[:, "bWendu"] = df["bWendu"].str.replace("℃","").astype('int32')
df.loc[:, "yWendu"] = df["yWendu"].str.replace("℃","").astype('int32')

# 新增列，温差
# 注意，df["bWendu"]其实是一个Series，后面的减法返回的是Series
df.loc[:, "wencha"] = df["bWendu"] - df["yWendu"]

```

(2)df.apply方法
Apply a function along an axis of the DataFrame.

Objects passed to the function are Series objects whose index is either the DataFrame’s index (axis=0) or the DataFrame’s columns (axis=1).

DataFrame.apply(func, axis=0, broadcast=False, raw=False, reduce=None, args=(), **kwds)

该函数最有用的是第一个参数，这个参数是函数，相当于C/C++的函数指针。

这个函数需要自己实现，函数的传入参数根据axis来定，我们在函数中实现对Series不同属性之间的计算，返回一个结果，则apply函数会自动遍历每一行DataFrame的数据，最后将所有结果组合成一个Series数据结构并返回。

```
# 实例：添加一列温度类型：

如果最高温度大于33度就是高温
低于-10度是低温
否则是常温

def get_wendu_type(x):
    if x["bWendu"] > 33:
        return '高温'
    if x["yWendu"] < -10:
        return '低温'
    return '常温'

# 注意需要设置axis==1，这是series的index是columns
df.loc[:, "wendu_type"] = df.apply(get_wendu_type, axis=1)


```

(3)df.assign方法

Assign new columns to a DataFrame.

Returns a new object with all original columns in addition to new ones.

```
# 将温度从摄氏度变成华氏度
# 可以同时添加多个新的列
df.assign(
    yWendu_huashi = lambda x : x["yWendu"] * 9 / 5 + 32,
    # 摄氏度转华氏度
    bWendu_huashi = lambda x : x["bWendu"] * 9 / 5 + 32
)
```
![]({{ "/assets/img/2020-08-08-10-58-48.png" |  }})

(4)按条件选择分组分别赋值

按条件先选择数据，然后对这部分数据赋值新列
```
# 高低温差大于10度，则认为温差大

# 先创建空列（这是第一种创建新列的方法）
df['wencha_type'] = ''

df.loc[df["bWendu"]-df["yWendu"]>10, "wencha_type"] = "温差大"

df.loc[df["bWendu"]-df["yWendu"]<=10, "wencha_type"] = "温差正常"

```

# 05 Pandas数据统计函数

- 汇总类统计
- 唯一去重和按值计算
- 相关系数和协方差

(1) 汇总类统计

```
# 一下子提取所有数字列统计结果
df.describe()
```
![]({{ "/assets/img/2020-08-08-11-08-35.png" |  }})

```
# 查看单个Series的数据
df["bWendu"].mean()
# 18.665753424657535

# 最高温
df["bWendu"].max()
# 38

# 最低温
df["bWendu"].min()
# -5
```

(2) 唯一去重和按值计数

- 唯一去重
  一般不用于数值列，而是枚举、分类列，了解某一列包含的全部取值有哪些（类比 select distinct）

```
df["fengxiang"].unique()
# array(['东北风', '北风', '西北风', '西南风', '南风', '东南风', '东风', '西风'], dtype=object)

```
- 按值计数
```
df["fengxiang"].value_counts()
# 结果按降序排列
南风     92
西南风    64
北风     54
西北风    51
东南风    46
东北风    38
东风     14
西风      6
Name: fengxiang, dtype: int64
```
(3) 相关系数和协方差
- 协方差：*衡量同向反向程度*，如果协方差为正，说明X，Y同向变化，协方差越大说明同向程度越高；如果协方差为负，说明X，Y反向运动，协方差越小说明反向程度越高。
- 相关系数：*衡量相似度程度*，当他们的相关系数为1时，说明两个变量变化时的正向相似度最大，当相关系数为－1时，说明两个变量变化的反向相似度最大

```
# 协方差矩阵：
df.cov()
```
![]({{ "/assets/img/2020-08-08-17-30-44.png" |  }})

```
# 相关系数矩阵
df.corr()
```
![]({{ "/assets/img/2020-08-08-17-31-08.png" |  }})

```
# 单独查看空气质量和最高温度的相关系数
df["aqi"].corr(df["bWendu"])
```

# 06 Pandas对缺失值的处理

清洗前

![]({{ "/assets/img/2020-08-09-10-30-13.png" |  }})

清洗后

![]({{ "/assets/img/2020-08-09-10-34-09.png" |  }})

Pandas使用这些函数处理缺失值：

- isnull和notnull：检测是否是空值，可用于df和series
- dropna：丢弃、删除缺失值
  - axis : 删除行还是列，{0 or ‘index’, 1 or ‘columns’}, default 0
  - how : 如果等于any则任何值为空都删除，如果等于all则所有值都为空才删除
  - inplace : 如果为True则修改当前df，否则返回新的df
- fillna：填充空值
  - value：用于填充的值，可以是单个值，或者字典（key是列名，value是值）
  - method : 等于ffill使用前一个不为空的值填充forword fill；等于bfill使用后一个不为空的值填充backword fill
  - axis : 按行还是列填充，{0 or ‘index’, 1 or ‘columns’}
  - inplace : 如果为True则修改当前df，否则返回新的df

(1) 步骤1：读取Excel时，**忽略前几个空行**

```
studf = pd.read_excel("./datas/student_excel/student_excel.xlsx", skiprows=2)
# skiprows=2，忽略前两个空行

```
![]({{ "/assets/img/2020-08-09-10-40-07.png" |  }})

(2)步骤2：检测空值

```
# 检查所有行和列是否为空
studf.isnull()

# 检查某个行或列是否为空
studf["分数"].isnull()
# 检查某个行或列是否非空
studf["分数"].notnull()

# 筛选没有空分数的所有行
studf.loc[stu["分数"].notnull(),:]

```

(3)步骤3：删除掉全是空值的列

```
studf.dropna(axis=1, how="all", inplace=True)
```
![]({{ "/assets/img/2020-08-09-10-54-06.png" |  }})

(4)步骤4：删除掉全为空值的行
```
studf.dropna(axis="index", how="all", inplace=True)
```
![]({{ "/assets/img/2020-08-09-10-55-24.png" |  }})

(5)步骤5：将分数列为空的填充为0分
```
studf.fillna({"分数"，0})
或者
studf.loc[:,'分数']=studf['分数'].fillna(0)

```
(6)步骤6：将姓名的缺失值进行填充
```
studf.loc[:,'姓名']=studf.fillna(method="ffill")
```
![]({{ "/assets/img/2020-08-09-11-10-06.png" |  }})

(7)步骤7：将清洗好的excel保存
```
studf.to_excel("./datas/student_excel/student_excel_clean.xlsx", index=False)
```

# 07 Pandas数据排序
Series的排序：
- Series.sort_values(ascending=True, inplace=False)
  - ascending：默认为True升序排序，为False降序排序
  - inplace：是否修改原始Series

DataFrame的排序：
- DataFrame.sort_values(by, ascending=True, inplace=False)
  - by：字符串或者List<字符串>，单列排序或者多列排序
  - ascending：bool或者List，升序还是降序，如果是list对应by的多列
  - inplace：是否修改原始DataFrame

```
# 多字段排序，分别指定升序和降序
df.sort_values(by=["aqiLevel", "bWendu"], ascending=[True, False])
```

# 08 Pandas字符串处理
Pandas的字符串处理：

- 使用方法：先获取Series的str属性，然后在属性上调用函数；
- 只能在**字符串列**上使用，不能数字列上使用；
- Dataframe上没有str属性和处理方法
- Series.str并不是Python原生字符串，而是自己的一套方法，不过大部分和原生str很相似；

> [Series.str字符串方法列表参考文档](https://pandas.pydata.org/pandas-docs/stable/reference/series.html#string-handling)

(1) 获取Series的str属性，使用各种字符串处理函数

(2) 使用str的startswith、contains等得到bool的Series可以做条件查询
```
condition = df["ymd"].str.startswith("2018-03")
```
得到bool的Series

![]({{ "/assets/img/2020-08-10-14-29-20.png" |  }})

```
df[condition].head()
```

![]({{ "/assets/img/2020-08-10-14-30-07.png" |  }})

(3) 需要多次str处理的链式操作

```
怎样提取201803这样的数字月份？
1、先将日期2018-03-31替换成20180331的形式
2、提取月份字符串201803

# 错误操作
df["ymd"].str.replace("-", "").slice(0, 6)
# 错误原因：'Series' object has no attribute 'slice'（slice位于str属性上，不属于Series对象）

# 正确操作
df["ymd"].str.replace("-", "").str.slice(0, 6)

# slice就是切片语法，可以直接用
df["ymd"].str.replace("-", "").str[0:6]

```
(4) 使用正则表达式的处理
可以在``Series.str.replace()``中使用正则表达式